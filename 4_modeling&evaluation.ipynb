{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "import random\n",
    "random.seed(335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic word\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better viz\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference\n",
    "-------------------\n",
    "\n",
    "- [pandas cheat sheet](https://github.com/pandas-dev/pandas/tree/master/doc/cheatsheet)\n",
    "- [numpy cheat sheet(data camp)](https://www.datacamp.com/community/blog/python-numpy-cheat-sheet)\n",
    "- [scikit-learn cheat sheet(data camp)](datacamp.com/community/blog/scikit-learn-cheat-sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RbelOPK4TFB"
   },
   "source": [
    "# modeling\n",
    "---------------------\n",
    "In this phase, various modeling techniques are selected and applied and their parameters are calibrated to optimal values. Typically, there are several techniques for the same data mining problem type. Some techniques have specific requirements on the form of data. Therefore, stepping back to the data preparation phase is often necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wfrdzmhe0Zfr"
   },
   "source": [
    "## select modeling techuique\n",
    "----------\n",
    "\n",
    "I used linear regression and gradient boosting methods\n",
    "\n",
    "First was used just as baseline, second was tested as useful model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTt2pAHhr8Od"
   },
   "source": [
    "## generate test design\n",
    "------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data, test_data) = data.randomSplit([0.7, 0.3], seed = 10)\n",
    "\n",
    "\n",
    "# A function to run commands\n",
    "import os\n",
    "def run(command):\n",
    "    return os.popen(command).read()\n",
    "\n",
    "train_data.select(\"scaledFeatures\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/train\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/train/*.json > data/train.json\")\n",
    "\n",
    "test_data.select(\"scaledFeatures\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/test\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/test/*.json > data/test.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAEHAkLIsImG"
   },
   "source": [
    "## build model\n",
    "----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.regression import LinearRegression  # Example model, replace with your actual model\n",
    "\n",
    "# Assuming you have already created a DataFrame 'data' and split it into training and test sets\n",
    "# train_data, test_data = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a LinearRegression instance (replace with your actual model)\n",
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "\n",
    "# Create a ParamGridBuilder and add the parameters to search over\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator instance\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                          numFolds=5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# Transform the data (Prediction)\n",
    "cvModel = crossval.fit(train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 33.1996\n",
      "R-squared (R²) on test data = 0.0685226\n",
      "Median Error on test data = 13.8065\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "\n",
    "predictions = cvModel.transform(test_data)\n",
    "# Evaluate the performance of the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(\"R-squared (R²) on test data = %g\" % r2)\n",
    "\n",
    "# Calculate the absolute error\n",
    "predictions = predictions.withColumn(\"error\", F.abs(predictions[\"label\"] - predictions[\"prediction\"]))\n",
    "\n",
    "# Calculate the median error\n",
    "median_error = predictions.approxQuantile(\"error\", [0.5], 0.01)[0]\n",
    "print(\"Median Error on test data = %g\" % median_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best maxDepth: 10\n",
      "Best maxIter: 10\n",
      "Best stepSize: 0.1\n",
      "Root Mean Squared Error (RMSE) on test data = 31.9557\n",
      "R-squared (R²) on test data = 0.137018\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "\n",
    "parameters = {\n",
    "    'maxDepth': [5, 10],\n",
    "    'maxIter': [5, 10]\n",
    "}\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, parameters['maxDepth'])\n",
    "             .addGrid(gbt.maxIter, parameters['maxIter'])\n",
    "             .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                          numFolds=3)\n",
    "\n",
    "cvModel = crossval.fit(train_data)\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "bestMaxDepth = bestModel._java_obj.getMaxDepth()\n",
    "bestMaxIter = bestModel._java_obj.getMaxIter()\n",
    "bestStepSize = bestModel._java_obj.getStepSize()\n",
    "\n",
    "print(f\"Best maxDepth: {bestMaxDepth}\")\n",
    "print(f\"Best maxIter: {bestMaxIter}\")\n",
    "print(f\"Best stepSize: {bestStepSize}\")\n",
    "\n",
    "predictions = cvModel.transform(test_data)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R-squared (R²) on test data = %g\" % r2)\n",
    "\n",
    "predictions = predictions.withColumn(\"difference\", abs(predictions[\"prediction\"] - predictions[\"label\"]))\n",
    "\n",
    "filtered_predictions = predictions.filter(predictions[\"difference\"] > 15)\n",
    "count_filtered = filtered_predictions.count()\n",
    "total_count = predictions.count()\n",
    "percentage = 100 - (count_filtered / total_count) * 100\n",
    "print(f\"Values with difference more than 15 percentage: {percentage:.2f}%\")\n",
    "\n",
    "predictions = predictions.withColumn(\"difference\", abs(predictions[\"prediction\"] - predictions[\"label\"]))\n",
    "\n",
    "filtered_predictions = predictions.filter(predictions[\"difference\"] > 30)\n",
    "\n",
    "count_filtered = filtered_predictions.count()\n",
    "\n",
    "total_count = predictions.count()\n",
    "\n",
    "percentage = 100 - (count_filtered / total_count) * 100\n",
    "\n",
    "print(f\"Values with difference more than 30 percentage: {percentage:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQn80GKbpYhOi2XJA3cST3",
   "collapsed_sections": [],
   "name": "modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
