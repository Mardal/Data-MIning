{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ff3ac9-e48a-41cf-b7b2-76668d2da938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             root_db|\n",
      "|     team0_projectdb|\n",
      "|team12_hive_proje...|\n",
      "|    team13_projectdb|\n",
      "|    team14_projectdb|\n",
      "|    team15_projectdb|\n",
      "|    team16_projectdb|\n",
      "|    team17_projectdb|\n",
      "|    team18_projectdb|\n",
      "|    team19_projectdb|\n",
      "|     team1_projectdb|\n",
      "|    team20_projectdb|\n",
      "|    team21_projectdb|\n",
      "|    team22_projectdb|\n",
      "|    team23_projectdb|\n",
      "|    team24_projectdb|\n",
      "|    team25_projectdb|\n",
      "|    team26_projectdb|\n",
      "|    team27_projectdb|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+----------------+--------------------+-----------+\n",
      "|       namespace|           tableName|isTemporary|\n",
      "+----------------+--------------------+-----------+\n",
      "|team37_projectdb|       airports_data|      false|\n",
      "|team37_projectdb|  airports_data_load|      false|\n",
      "|team37_projectdb|         flight_data|      false|\n",
      "|team37_projectdb|flight_data_bucketed|      false|\n",
      "|team37_projectdb|          q1_results|      false|\n",
      "|team37_projectdb|          q2_results|      false|\n",
      "|team37_projectdb|          q3_results|      false|\n",
      "|team37_projectdb|          q4_results|      false|\n",
      "|team37_projectdb|          q5_results|      false|\n",
      "|team37_projectdb|          route_data|      false|\n",
      "|team37_projectdb|route_data_partit...|      false|\n",
      "+----------------+--------------------+-----------+\n",
      "\n",
      "+----------+--------+---------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+------------+--------+------+--------+\n",
      "|   fl_date|dot_code|fl_number|crs_dep_time|dep_time|dep_delay|taxi_out|wheels_off|wheels_on|taxi_in|crs_arr_time|arr_time|arr_delay|cancelled|cancellation_code|diverted|crs_elapsed_time|elapsed_time|air_time|    id|route_id|\n",
      "+----------+--------+---------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+------------+--------+------+--------+\n",
      "|2021-06-08|   19393|     5448|        1100|  1120.0|     20.0|    12.0|    1132.0|   1153.0|    3.0|        1145|  1156.0|     11.0|      0.0|                N|     0.0|           105.0|        96.0|    81.0|624813|     407|\n",
      "|2021-06-08|   19393|     2427|        1705|  1703.0|     -2.0|     9.0|    1712.0|   1732.0|    4.0|        1750|  1736.0|    -14.0|      0.0|                N|     0.0|           105.0|        93.0|    80.0|624810|     407|\n",
      "|2021-06-08|   19393|     2387|        1130|  1127.0|     -3.0|    14.0|    1141.0|   1305.0|    5.0|        1315|  1310.0|     -5.0|      0.0|                N|     0.0|           165.0|       163.0|   144.0|624735|     963|\n",
      "|2021-06-08|   19393|     3751|         635|   635.0|      0.0|    11.0|     646.0|   1031.0|    5.0|        1040|  1036.0|     -4.0|      0.0|                N|     0.0|           185.0|       181.0|   165.0|624590|    1206|\n",
      "|2021-06-08|   19393|     5537|         615|   616.0|      1.0|     6.0|     622.0|    811.0|    7.0|         830|   818.0|    -12.0|      0.0|                N|     0.0|           255.0|       242.0|   229.0|624587|     362|\n",
      "|2021-06-08|   19393|     5140|        2130|  2221.0|     51.0|    13.0|    2234.0|     26.0|    4.0|        2345|    30.0|     45.0|      0.0|                N|     0.0|           255.0|       249.0|   232.0|624585|     362|\n",
      "|2021-06-08|   19393|     3822|        1805|  1839.0|     34.0|    17.0|    1856.0|   2045.0|    6.0|        2020|  2051.0|     31.0|      0.0|                N|     0.0|           255.0|       252.0|   229.0|624584|     362|\n",
      "|2021-06-08|   19393|     4306|        1930|  1933.0|      3.0|    10.0|    1943.0|   2043.0|   26.0|        2100|  2109.0|      9.0|      0.0|                N|     0.0|           150.0|       156.0|   120.0|624479|     391|\n",
      "|2021-06-08|   19393|     2652|         625|   620.0|     -5.0|    16.0|     636.0|   1054.0|    4.0|        1125|  1058.0|    -27.0|      0.0|                N|     0.0|           180.0|       158.0|   138.0|624439|    1118|\n",
      "|2021-06-08|   19393|     3500|        1620|  1646.0|     26.0|     9.0|    1655.0|   1743.0|    7.0|        1735|  1750.0|     15.0|      0.0|                N|     0.0|            75.0|        64.0|    48.0|624378|     344|\n",
      "+----------+--------+---------+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+------------+--------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCols\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Add here your team number teamx\n",
    "team = 37\n",
    "\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "spark.sql(\"USE team37_projectdb\").show()\n",
    "spark.sql(\"SHOW TABLES\").show()\n",
    "spark.sql(\"SELECT * FROM team37_projectdb.flight_data_bucketed LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14c4043-d682-42af-8767-1d3a1b2e4582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(fl_date='2021-06-08', dot_code=19393, fl_number=5448, crs_dep_time=1100, dep_time=1120.0, dep_delay=20.0, taxi_out=12.0, wheels_off=1132.0, wheels_on=1153.0, taxi_in=3.0, crs_arr_time=1145, arr_time=1156.0, arr_delay=11.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=96.0, air_time=81.0, id=624813, route_id=407),\n",
       " Row(fl_date='2021-06-08', dot_code=19393, fl_number=2427, crs_dep_time=1705, dep_time=1703.0, dep_delay=-2.0, taxi_out=9.0, wheels_off=1712.0, wheels_on=1732.0, taxi_in=4.0, crs_arr_time=1750, arr_time=1736.0, arr_delay=-14.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=93.0, air_time=80.0, id=624810, route_id=407),\n",
       " Row(fl_date='2021-06-08', dot_code=19393, fl_number=2387, crs_dep_time=1130, dep_time=1127.0, dep_delay=-3.0, taxi_out=14.0, wheels_off=1141.0, wheels_on=1305.0, taxi_in=5.0, crs_arr_time=1315, arr_time=1310.0, arr_delay=-5.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=165.0, elapsed_time=163.0, air_time=144.0, id=624735, route_id=963),\n",
       " Row(fl_date='2021-06-08', dot_code=19393, fl_number=3751, crs_dep_time=635, dep_time=635.0, dep_delay=0.0, taxi_out=11.0, wheels_off=646.0, wheels_on=1031.0, taxi_in=5.0, crs_arr_time=1040, arr_time=1036.0, arr_delay=-4.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=185.0, elapsed_time=181.0, air_time=165.0, id=624590, route_id=1206),\n",
       " Row(fl_date='2021-06-08', dot_code=19393, fl_number=5537, crs_dep_time=615, dep_time=616.0, dep_delay=1.0, taxi_out=6.0, wheels_off=622.0, wheels_on=811.0, taxi_in=7.0, crs_arr_time=830, arr_time=818.0, arr_delay=-12.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=255.0, elapsed_time=242.0, air_time=229.0, id=624587, route_id=362)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = spark.read.format(\"avro\").table('team37_projectdb.flight_data_bucketed')\n",
    "flights.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e51ce5-d9c0-4a6a-8239-e2ce2f6b1825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dest='LAS', origin_city='Albuquerque, NM', dest_city='Las Vegas, NV', route_id=11, most_common_distance=486.0, origin='ABQ'),\n",
       " Row(dest='PHX', origin_city='Albuquerque, NM', dest_city='Phoenix, AZ', route_id=17, most_common_distance=328.0, origin='ABQ'),\n",
       " Row(dest='MDW', origin_city='Albuquerque, NM', dest_city='Chicago, IL', route_id=18, most_common_distance=1121.0, origin='ABQ'),\n",
       " Row(dest='HOU', origin_city='Albuquerque, NM', dest_city='Houston, TX', route_id=19, most_common_distance=759.0, origin='ABQ'),\n",
       " Row(dest='DEN', origin_city='Albuquerque, NM', dest_city='Denver, CO', route_id=20, most_common_distance=349.0, origin='ABQ')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes = spark.read.format(\"avro\").table('team37_projectdb.route_data_partitioned')\n",
    "routes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9860bdd7-577b-41bd-92d0-e310c3d7287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(airport_name='ABQ', origin_latitude=35.04022216796875, origin_longitude=-106.60919189453125),\n",
       " Row(airport_name='ANC', origin_latitude=61.174320220947266, origin_longitude=-149.99618530273438),\n",
       " Row(airport_name='ATL', origin_latitude=33.640445709228516, origin_longitude=-84.42694091796875),\n",
       " Row(airport_name='AUS', origin_latitude=30.19453239440918, origin_longitude=-97.66986846923828),\n",
       " Row(airport_name='BDL', origin_latitude=41.938873291015625, origin_longitude=-72.6832275390625)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports = spark.read.format(\"avro\").table('team37_projectdb.airports_data_load').withColumnRenamed(\"latitude\", \"origin_latitude\").withColumnRenamed(\"longitude\", \"origin_longitude\")\n",
    "airports.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a2e44f7-276d-4780-97a8-204925abe964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dest_airport_name='ABQ', dest_latitude=35.04022216796875, dest_longitude=-106.60919189453125),\n",
       " Row(dest_airport_name='ANC', dest_latitude=61.174320220947266, dest_longitude=-149.99618530273438),\n",
       " Row(dest_airport_name='ATL', dest_latitude=33.640445709228516, dest_longitude=-84.42694091796875),\n",
       " Row(dest_airport_name='AUS', dest_latitude=30.19453239440918, dest_longitude=-97.66986846923828),\n",
       " Row(dest_airport_name='BDL', dest_latitude=41.938873291015625, dest_longitude=-72.6832275390625)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports1 = spark.read.format(\"avro\").table('team37_projectdb.airports_data_load').withColumnRenamed(\"latitude\", \"dest_latitude\").withColumnRenamed(\"longitude\", \"dest_longitude\").withColumnRenamed(\"airport_name\", \"dest_airport_name\")\n",
    "airports1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60116cb-c0cb-48d3-8142-613aa2bebb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(route_id=407, fl_date='2021-06-08', dot_code=19393, fl_number=5448, crs_dep_time=1100, dep_time=1120.0, dep_delay=20.0, taxi_out=12.0, wheels_off=1132.0, wheels_on=1153.0, taxi_in=3.0, crs_arr_time=1145, arr_time=1156.0, arr_delay=11.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=96.0, air_time=81.0, id=624813, dest='MSY', origin_city='Orlando, FL', dest_city='New Orleans, LA', most_common_distance=551.0, origin='MCO', dest_airport_name='MSY', dest_latitude=29.993389129638672, dest_longitude=-90.25802612304688, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = flights.join(routes, on='route_id', how='inner')\n",
    "df = df.join(airports1, df.dest == airports1.dest_airport_name, how='inner')\n",
    "df = df.join(airports, df.origin == airports.airport_name, how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba63cd28-75d0-41b0-84e0-9458466b0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Transformer, HasInputCol, HasOutputCols,\n",
    "              DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def __init__(self, inputCol, outputCols, n):\n",
    "        super(Encoder, self).__init__()\n",
    "        self._set(inputCol=inputCol, outputCols=outputCols)\n",
    "        self.n = n\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        input_col = self.getInputCol()\n",
    "        output_cols = self.getOutputCols()\n",
    "        dataset = dataset.withColumn(output_cols[0],\n",
    "                                     F.sin(2 * math.pi*F.col(input_col) / self.n))\n",
    "        return dataset\n",
    "\n",
    "\n",
    "df = df.withColumn(\"year\", F.year(\"fl_date\"))\n",
    "df = df.withColumn(\"month\", F.month(\"fl_date\"))\n",
    "df = df.withColumn(\"day\", F.dayofmonth(\"fl_date\"))\n",
    "df = Encoder(\"month\", [\"month\"], 12).transform(df)\n",
    "df = Encoder(\"day\", [\"day\"], 31).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f90f1119-f510-46e2-bcc6-e01600d5a014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(route_id=407, fl_date='2021-06-08', dot_code=19393, fl_number=5448, crs_dep_time=1100, dep_time=1120.0, dep_delay=20.0, taxi_out=12.0, wheels_off=1132.0, wheels_on=1153.0, taxi_in=3.0, crs_arr_time=1145, arr_time=1156.0, arr_delay=11.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=96.0, air_time=81.0, id=624813, dest='MSY', origin_city='Orlando, FL', dest_city='New Orleans, LA', most_common_distance=551.0, origin='MCO', dest_airport_name='MSY', dest_latitude=29.993389129638672, dest_longitude=-90.25802612304688, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528),\n",
       " Row(route_id=407, fl_date='2021-06-08', dot_code=19393, fl_number=2427, crs_dep_time=1705, dep_time=1703.0, dep_delay=-2.0, taxi_out=9.0, wheels_off=1712.0, wheels_on=1732.0, taxi_in=4.0, crs_arr_time=1750, arr_time=1736.0, arr_delay=-14.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=93.0, air_time=80.0, id=624810, dest='MSY', origin_city='Orlando, FL', dest_city='New Orleans, LA', most_common_distance=551.0, origin='MCO', dest_airport_name='MSY', dest_latitude=29.993389129638672, dest_longitude=-90.25802612304688, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528),\n",
       " Row(route_id=963, fl_date='2021-06-08', dot_code=19393, fl_number=2387, crs_dep_time=1130, dep_time=1127.0, dep_delay=-3.0, taxi_out=14.0, wheels_off=1141.0, wheels_on=1305.0, taxi_in=5.0, crs_arr_time=1315, arr_time=1310.0, arr_delay=-5.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=165.0, elapsed_time=163.0, air_time=144.0, id=624735, dest='MCI', origin_city='Orlando, FL', dest_city='Kansas City, MO', most_common_distance=1072.0, origin='MCO', dest_airport_name='MCI', dest_latitude=39.297603607177734, dest_longitude=-94.71390533447266, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528),\n",
       " Row(route_id=1206, fl_date='2021-06-08', dot_code=19393, fl_number=3751, crs_dep_time=635, dep_time=635.0, dep_delay=0.0, taxi_out=11.0, wheels_off=646.0, wheels_on=1031.0, taxi_in=5.0, crs_arr_time=1040, arr_time=1036.0, arr_delay=-4.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=185.0, elapsed_time=181.0, air_time=165.0, id=624590, dest='MCO', origin_city='Minneapolis, MN', dest_city='Orlando, FL', most_common_distance=1310.0, origin='MSP', dest_airport_name='MCO', dest_latitude=28.42888832092285, dest_longitude=-81.31602478027344, airport_name='MSP', origin_latitude=44.88054656982422, origin_longitude=-93.2169189453125, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528),\n",
       " Row(route_id=362, fl_date='2021-06-08', dot_code=19393, fl_number=5537, crs_dep_time=615, dep_time=616.0, dep_delay=1.0, taxi_out=6.0, wheels_off=622.0, wheels_on=811.0, taxi_in=7.0, crs_arr_time=830, arr_time=818.0, arr_delay=-12.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=255.0, elapsed_time=242.0, air_time=229.0, id=624587, dest='LAX', origin_city='Chicago, IL', dest_city='Los Angeles, CA', most_common_distance=1750.0, origin='MDW', dest_airport_name='LAX', dest_latitude=33.942535400390625, dest_longitude=-118.40807342529297, airport_name='MDW', origin_latitude=41.78598403930664, origin_longitude=-87.75242614746094, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18423ef7-55de-454c-9e9d-49e757f682a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fl_number',\n",
       " 'crs_dep_time',\n",
       " 'dep_time',\n",
       " 'dep_delay',\n",
       " 'taxi_out',\n",
       " 'wheels_off',\n",
       " 'wheels_on',\n",
       " 'taxi_in',\n",
       " 'crs_arr_time',\n",
       " 'arr_time',\n",
       " 'arr_delay',\n",
       " 'cancelled',\n",
       " 'cancellation_code',\n",
       " 'diverted',\n",
       " 'crs_elapsed_time',\n",
       " 'elapsed_time',\n",
       " 'air_time',\n",
       " 'id',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'airport_name',\n",
       " 'dest_latitude',\n",
       " 'dest_longitude',\n",
       " 'origin_latitude',\n",
       " 'origin_longitude']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['crs_dep_time', 'dep_time', 'dep_delay', \n",
    "            'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in', 'crs_arr_time', 'arr_time', 'arr_delay', 'cancelled',\n",
    "            'cancellation_code', 'diverted', 'crs_elapsed_time', 'elapsed_time', 'air_time','id', 'year', 'month', 'day', 'airport_name', 'dest_latitude', 'dest_longitude', 'origin_latitude', 'origin_longitude']\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f30d5912-29f0-41f6-8c4c-c3f1fa5ec75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(route_id=407, fl_date='2021-06-08', dot_code=19393, fl_number=5448, crs_dep_time=1100, dep_time=1120.0, dep_delay=20.0, taxi_out=12.0, wheels_off=1132.0, wheels_on=1153.0, taxi_in=3.0, crs_arr_time=1145, arr_time=1156.0, arr_delay=11.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=96.0, air_time=81.0, id=624813, dest='MSY', origin_city='Orlando, FL', dest_city='New Orleans, LA', most_common_distance=551.0, origin='MCO', dest_airport_name='MSY', dest_latitude=29.993389129638672, dest_longitude=-90.25802612304688, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528, crs_dep_time_hours=0.258819045102521, dep_time_hours=0.258819045102521, wheels_off_hours=0.258819045102521, wheels_on_hours=0.258819045102521, crs_arr_time_hours=0.258819045102521, arr_time_hours=0.258819045102521),\n",
       " Row(route_id=407, fl_date='2021-06-08', dot_code=19393, fl_number=2427, crs_dep_time=1705, dep_time=1703.0, dep_delay=-2.0, taxi_out=9.0, wheels_off=1712.0, wheels_on=1732.0, taxi_in=4.0, crs_arr_time=1750, arr_time=1736.0, arr_delay=-14.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=93.0, air_time=80.0, id=624810, dest='MSY', origin_city='Orlando, FL', dest_city='New Orleans, LA', most_common_distance=551.0, origin='MCO', dest_airport_name='MSY', dest_latitude=29.993389129638672, dest_longitude=-90.25802612304688, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528, crs_dep_time_hours=-0.9659258262890683, dep_time_hours=-0.9659258262890683, wheels_off_hours=-0.9659258262890683, wheels_on_hours=-0.9659258262890683, crs_arr_time_hours=-0.9659258262890683, arr_time_hours=-0.9659258262890683),\n",
       " Row(route_id=963, fl_date='2021-06-08', dot_code=19393, fl_number=2387, crs_dep_time=1130, dep_time=1127.0, dep_delay=-3.0, taxi_out=14.0, wheels_off=1141.0, wheels_on=1305.0, taxi_in=5.0, crs_arr_time=1315, arr_time=1310.0, arr_delay=-5.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=165.0, elapsed_time=163.0, air_time=144.0, id=624735, dest='MCI', origin_city='Orlando, FL', dest_city='Kansas City, MO', most_common_distance=1072.0, origin='MCO', dest_airport_name='MCI', dest_latitude=39.297603607177734, dest_longitude=-94.71390533447266, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528, crs_dep_time_hours=0.258819045102521, dep_time_hours=0.258819045102521, wheels_off_hours=0.258819045102521, wheels_on_hours=-0.2588190451025208, crs_arr_time_hours=-0.2588190451025208, arr_time_hours=-0.2588190451025208),\n",
       " Row(route_id=1206, fl_date='2021-06-08', dot_code=19393, fl_number=3751, crs_dep_time=635, dep_time=635.0, dep_delay=0.0, taxi_out=11.0, wheels_off=646.0, wheels_on=1031.0, taxi_in=5.0, crs_arr_time=1040, arr_time=1036.0, arr_delay=-4.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=185.0, elapsed_time=181.0, air_time=165.0, id=624590, dest='MCO', origin_city='Minneapolis, MN', dest_city='Orlando, FL', most_common_distance=1310.0, origin='MSP', dest_airport_name='MCO', dest_latitude=28.42888832092285, dest_longitude=-81.31602478027344, airport_name='MSP', origin_latitude=44.88054656982422, origin_longitude=-93.2169189453125, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528, crs_dep_time_hours=1.0, dep_time_hours=1.0, wheels_off_hours=1.0, wheels_on_hours=0.49999999999999994, crs_arr_time_hours=0.49999999999999994, arr_time_hours=0.49999999999999994),\n",
       " Row(route_id=362, fl_date='2021-06-08', dot_code=19393, fl_number=5537, crs_dep_time=615, dep_time=616.0, dep_delay=1.0, taxi_out=6.0, wheels_off=622.0, wheels_on=811.0, taxi_in=7.0, crs_arr_time=830, arr_time=818.0, arr_delay=-12.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=255.0, elapsed_time=242.0, air_time=229.0, id=624587, dest='LAX', origin_city='Chicago, IL', dest_city='Los Angeles, CA', most_common_distance=1750.0, origin='MDW', dest_airport_name='LAX', dest_latitude=33.942535400390625, dest_longitude=-118.40807342529297, airport_name='MDW', origin_latitude=41.78598403930664, origin_longitude=-87.75242614746094, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528, crs_dep_time_hours=1.0, dep_time_hours=1.0, wheels_off_hours=1.0, wheels_on_hours=0.8660254037844387, crs_arr_time_hours=0.8660254037844387, arr_time_hours=0.8660254037844387)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, floor, abs\n",
    "def split_time(column_name):\n",
    "    hours = floor(col(column_name) / 100).alias(f\"{column_name}_hours\")\n",
    "    return hours\n",
    "\n",
    "time_columns = [\"crs_dep_time\", \"dep_time\", \"wheels_off\", \"wheels_on\", \"crs_arr_time\", \"arr_time\"]\n",
    "for col_name in time_columns:\n",
    "    hours = split_time(col_name)\n",
    "    df = df.withColumn(f\"{col_name}_hours\", hours)\n",
    "df = Encoder(\"crs_dep_time_hours\", [\"crs_dep_time_hours\"], 24).transform(df)\n",
    "df = Encoder(\"dep_time_hours\", [\"dep_time_hours\"], 24).transform(df)\n",
    "df = Encoder(\"wheels_off_hours\", [\"wheels_off_hours\"], 24).transform(df)\n",
    "df = Encoder(\"wheels_on_hours\", [\"wheels_on_hours\"], 24).transform(df)\n",
    "df = Encoder(\"crs_arr_time_hours\", [\"crs_arr_time_hours\"], 24).transform(df)\n",
    "df = Encoder(\"arr_time_hours\", [\"arr_time_hours\"], 24).transform(df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05300c34-906a-4d0d-ba34-f2f52d550374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(route_id=407, fl_date='2021-06-08', dot_code=19393, fl_number=5448, crs_dep_time=1100, dep_time=1120.0, dep_delay=20.0, taxi_out=12.0, wheels_off=1132.0, wheels_on=1153.0, taxi_in=3.0, crs_arr_time=1145, arr_time=1156.0, arr_delay=11.0, cancelled=0.0, cancellation_code='N', diverted=0.0, crs_elapsed_time=105.0, elapsed_time=96.0, air_time=81.0, id=624813, dest='MSY', origin_city='Orlando, FL', dest_city='New Orleans, LA', most_common_distance=551.0, origin='MCO', dest_airport_name='MSY', dest_latitude=29.993389129638672, dest_longitude=-90.25802612304688, airport_name='MCO', origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528, crs_dep_time_hours=0.258819045102521, dep_time_hours=0.258819045102521, wheels_off_hours=0.258819045102521, wheels_on_hours=0.258819045102521, crs_arr_time_hours=0.258819045102521, arr_time_hours=0.258819045102521)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f57ad4af-bae7-4454-ac34-fa5f90d56897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taxi_out',\n",
       " 'taxi_in',\n",
       " 'arr_delay',\n",
       " 'diverted',\n",
       " 'crs_elapsed_time',\n",
       " 'elapsed_time',\n",
       " 'air_time',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'airport_name',\n",
       " 'dest_latitude',\n",
       " 'dest_longitude',\n",
       " 'origin_latitude',\n",
       " 'origin_longitude',\n",
       " 'crs_dep_time_hours',\n",
       " 'dep_time_hours',\n",
       " 'wheels_off_hours',\n",
       " 'wheels_on_hours',\n",
       " 'crs_arr_time_hours',\n",
       " 'arr_time_hours']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['taxi_out', 'taxi_in', 'arr_delay', 'diverted', 'crs_elapsed_time', 'elapsed_time', 'air_time', 'year', 'month', 'day', 'airport_name', 'dest_latitude', 'dest_longitude', 'origin_latitude', 'origin_longitude', 'crs_dep_time_hours',\n",
    "            'dep_time_hours', 'wheels_off_hours', 'wheels_on_hours', 'crs_arr_time_hours', 'arr_time_hours']\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16b2284d-4624-4b3d-994f-9850c3a2b98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(taxi_out=12.0, taxi_in=3.0, label=11.0, diverted=0.0, crs_elapsed_time=105.0, elapsed_time=96.0, air_time=81.0, year=2021, month=1.2246467991473532e-16, day=0.9987165071710528, airport_name='MCO', dest_latitude=29.993389129638672, dest_longitude=-90.25802612304688, origin_latitude=28.42888832092285, origin_longitude=-81.31602478027344, crs_dep_time_hours=0.258819045102521, dep_time_hours=0.258819045102521, wheels_off_hours=0.258819045102521, wheels_on_hours=0.258819045102521, crs_arr_time_hours=0.258819045102521, arr_time_hours=0.258819045102521)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.select(*features)\n",
    "df_filtered = df_filtered.withColumnRenamed(\"arr_delay\",\"label\")\n",
    "df_filtered.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da4bd7d2-583a-49ba-8fdf-218f984714f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=11.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, 5.5993, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, -0.4096, -1.1398, -0.1123, 1.3921, -1.0705, 0.5206, -1.3724, 1.027, 0.442, 0.7807])),\n",
       " Row(label=-14.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, 5.5993, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, -0.4096, -1.1398, -0.1123, 1.3921, -1.0705, 0.5206, -1.3724, 1.027, -1.1635, -1.0782])),\n",
       " Row(label=-5.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, 5.5993, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, 0.6447, -1.1398, -0.1123, 1.3921, 0.7267, 0.2684, -1.3724, 1.027, 0.442, -0.005])),\n",
       " Row(label=-4.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, -0.1786, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, 14.849, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, 0.9961, -1.1398, -0.1123, 1.3921, -1.3727, 1.0268, 1.8058, 0.3531, 1.4137, 1.1467])),\n",
       " Row(label=-12.0, scaledFeatures=DenseVector([-0.2679, -0.244, 4.1218, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, -0.1786, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, 2.2261, -1.1398, -0.1123, 1.3921, -0.3077, -1.073, 1.208, 0.6626, 1.4137, 1.7023]))]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler,StandardScaler, Word2Vec, Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "categoricalCols = ['airport_name']\n",
    "others = ['crs_elapsed_time', 'year', 'month', 'day', 'dest_latitude', 'dest_longitude', 'origin_latitude', 'origin_longitude', 'crs_dep_time_hours', 'crs_arr_time_hours']\n",
    "\n",
    "# StringIndexer for categorical columns\n",
    "indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)).setHandleInvalid(\"skip\") for c in categoricalCols ]\n",
    "\n",
    "# OneHotEncoder for indexed categorical columns\n",
    "encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers ]\n",
    "\n",
    "# VectorAssembler to combine all features into a single vector\n",
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders] + others, outputCol=\"features\")\n",
    "\n",
    "# StandardScaler to scale the features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "\n",
    "# Create the pipeline with all stages\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "model = pipeline.fit(df_filtered)\n",
    "\n",
    "# Transform the data\n",
    "data = model.transform(df_filtered)\n",
    "data.select('label', 'scaledFeatures').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e59ce363-f2be-4ed6-bad7-5a71765d50b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  split the data into 60% training and 40% test (it is not stratified)\n",
    "(train_data, test_data) = data.randomSplit([0.7, 0.3], seed = 10)\n",
    "\n",
    "\n",
    "# A function to run commands\n",
    "import os\n",
    "def run(command):\n",
    "    return os.popen(command).read()\n",
    "\n",
    "train_data.select(\"scaledFeatures\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/train\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/train/*.json > data/train.json\")\n",
    "\n",
    "test_data.select(\"scaledFeatures\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/test\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/test/*.json > data/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7ece1cad-94fa-45de-ba10-6466ec253986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.regression import LinearRegression  # Example model, replace with your actual model\n",
    "\n",
    "# Assuming you have already created a DataFrame 'data' and split it into training and test sets\n",
    "# train_data, test_data = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a LinearRegression instance (replace with your actual model)\n",
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "\n",
    "# Create a ParamGridBuilder and add the parameters to search over\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator instance\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                          numFolds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "39619184-382e-44de-88fc-3e75fa1f6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data (Prediction)\n",
    "cvModel = crossval.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7676143d-4af7-48a0-8698-7c8eb304e229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 33.1996\n",
      "R-squared (R²) on test data = 0.0685226\n",
      "Median Error on test data = 13.8065\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "\n",
    "predictions = cvModel.transform(test_data)\n",
    "# Evaluate the performance of the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(\"R-squared (R²) on test data = %g\" % r2)\n",
    "\n",
    "# Calculate the absolute error\n",
    "predictions = predictions.withColumn(\"error\", F.abs(predictions[\"label\"] - predictions[\"prediction\"]))\n",
    "\n",
    "# Calculate the median error\n",
    "median_error = predictions.approxQuantile(\"error\", [0.5], 0.01)[0]\n",
    "print(\"Median Error on test data = %g\" % median_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e360c82c-765d-4c73-8e18-f382be411468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=11.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, 5.5993, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, -0.0787, -0.5237, 0.0, -0.4096, -0.3939, -1.1398, -0.1123, 1.3921, -1.0705, 0.5206, -1.3724, 1.027, 0.442, 0.4777, 0.7288, 0.7807])),\n",
       " Row(label=-14.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, 5.5993, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, -0.5532, -0.3345, 0.0, -0.4096, -0.4118, -1.1398, -0.1123, 1.3921, -1.0705, 0.5206, -1.3724, 1.027, -1.1635, -1.1538, -1.0971, -1.0782])),\n",
       " Row(label=-5.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, 5.5993, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, 0.2376, -0.1453, 0.0, 0.6447, 0.7355, -1.1398, -0.1123, 1.3921, 0.7267, 0.2684, -1.3724, 1.027, 0.442, 0.4777, -0.0429, -0.005])),\n",
       " Row(label=-4.0, scaledFeatures=DenseVector([-0.2679, -0.244, -0.2426, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, -0.1786, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, 14.849, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, -0.2369, -0.1453, 0.0, 0.9961, 1.112, -1.1398, -0.1123, 1.3921, -1.3727, 1.0268, 1.8058, 0.3531, 1.4137, 1.4651, 1.0883, 1.1467])),\n",
       " Row(label=-12.0, scaledFeatures=DenseVector([-0.2679, -0.244, 4.1218, -0.2296, -0.2285, -0.223, -0.1974, -0.1868, -0.1786, -0.169, -0.1638, -0.1612, -0.1558, -0.1539, -0.1512, -0.1498, -0.143, -0.1375, -0.1212, -0.12, -0.116, -0.1154, -0.1132, -0.1023, -0.1014, -0.0999, -0.0975, -0.0934, -0.0902, -0.089, -0.0888, -0.086, -0.0853, -0.0819, -0.0814, -0.0813, -0.0802, -0.0802, -0.0798, -0.0784, -0.0768, -0.0746, -0.0742, -0.0732, -0.0729, -0.0726, -0.068, -0.0673, -0.0663, -0.0649, -0.0602, -0.0592, -0.0584, -0.0583, -0.058, -0.0574, -0.0573, -0.057, -0.0569, -0.0562, -0.0555, -0.0545, -0.0536, -0.0536, -0.0529, -0.0525, -0.0511, -0.051, -0.051, -0.0504, -0.0494, -0.0476, -0.0475, -0.0471, -0.0467, -0.0456, -0.0455, -0.045, -0.0423, -0.0423, -0.0419, -0.0418, -0.0412, -0.0403, -0.0394, -0.0391, -0.0391, -0.0384, -0.038, -0.0365, -0.0364, -0.0361, -0.0347, -0.0343, -0.0339, -0.0329, -0.0327, -0.0326, -0.0325, -0.0309, -0.0298, -0.0291, -0.024, -0.0239, -0.0238, -1.0278, 0.2332, 0.0, 2.2261, 2.2594, -1.1398, -0.1123, 1.3921, -0.3077, -1.073, 1.208, 0.6626, 1.4137, 1.4651, 1.634, 1.7023]))]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('label', 'scaledFeatures').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "95fa0a6a-35bd-4e73-8ebd-609693d40d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best maxDepth: 10\n",
      "Best maxIter: 10\n",
      "Best stepSize: 0.1\n",
      "Root Mean Squared Error (RMSE) on test data = 31.9557\n",
      "R-squared (R²) on test data = 0.137018\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "\n",
    "parameters = {\n",
    "    'maxDepth': [5, 10],\n",
    "    'maxIter': [5, 10]\n",
    "}\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, parameters['maxDepth'])\n",
    "             .addGrid(gbt.maxIter, parameters['maxIter'])\n",
    "             .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                          numFolds=3)\n",
    "\n",
    "cvModel = crossval.fit(train_data)\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "bestMaxDepth = bestModel._java_obj.getMaxDepth()\n",
    "bestMaxIter = bestModel._java_obj.getMaxIter()\n",
    "bestStepSize = bestModel._java_obj.getStepSize()\n",
    "\n",
    "print(f\"Best maxDepth: {bestMaxDepth}\")\n",
    "print(f\"Best maxIter: {bestMaxIter}\")\n",
    "print(f\"Best stepSize: {bestStepSize}\")\n",
    "\n",
    "predictions = cvModel.transform(test_data)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R-squared (R²) on test data = %g\" % r2)\n",
    "\n",
    "predictions = predictions.withColumn(\"difference\", abs(predictions[\"prediction\"] - predictions[\"label\"]))\n",
    "\n",
    "filtered_predictions = predictions.filter(predictions[\"difference\"] > 15)\n",
    "count_filtered = filtered_predictions.count()\n",
    "total_count = predictions.count()\n",
    "percentage = 100 - (count_filtered / total_count) * 100\n",
    "print(f\"Values with difference more than 15 percentage: {percentage:.2f}%\")\n",
    "\n",
    "predictions = predictions.withColumn(\"difference\", abs(predictions[\"prediction\"] - predictions[\"label\"]))\n",
    "\n",
    "# Фильтрация строк, где разница больше 15\n",
    "filtered_predictions = predictions.filter(predictions[\"difference\"] > 30)\n",
    "\n",
    "# Подсчет количества строк, удовлетворяющих условию\n",
    "count_filtered = filtered_predictions.count()\n",
    "\n",
    "# Подсчет общего количества строк\n",
    "total_count = predictions.count()\n",
    "\n",
    "# Вычисление процента\n",
    "percentage = 100 - (count_filtered / total_count) * 100\n",
    "\n",
    "print(f\"Values with difference more than 30 percentage: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e879f68-66c0-4ba1-b691-012014019db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96b57e72-e0b7-402a-9225-4e4441bb4751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=-7.0, prediction=-5.388233256649711),\n",
       " Row(label=-5.0, prediction=-5.056045857875219),\n",
       " Row(label=2.0, prediction=-1.9470859154672695),\n",
       " Row(label=-20.0, prediction=-2.9140579568598444),\n",
       " Row(label=-13.0, prediction=-9.425467671679812),\n",
       " Row(label=145.0, prediction=94.46382661960885),\n",
       " Row(label=-25.0, prediction=-14.491353560896588),\n",
       " Row(label=27.0, prediction=0.21488295823403436),\n",
       " Row(label=-19.0, prediction=-10.536535911863176),\n",
       " Row(label=-11.0, prediction=-11.13712881100392),\n",
       " Row(label=21.0, prediction=12.386829270286709),\n",
       " Row(label=13.0, prediction=-3.521745950829096),\n",
       " Row(label=62.0, prediction=36.44159109272692),\n",
       " Row(label=-25.0, prediction=-13.21756540006213),\n",
       " Row(label=-34.0, prediction=0.09165002231097907),\n",
       " Row(label=-27.0, prediction=-20.670082923869703),\n",
       " Row(label=-13.0, prediction=-6.755880797363504),\n",
       " Row(label=-12.0, prediction=-9.028539984178078),\n",
       " Row(label=97.0, prediction=52.61430963400014),\n",
       " Row(label=191.0, prediction=223.80455037167746),\n",
       " Row(label=-39.0, prediction=-19.119650739615725),\n",
       " Row(label=-26.0, prediction=-11.584934765591708),\n",
       " Row(label=-19.0, prediction=12.417663791663006),\n",
       " Row(label=-17.0, prediction=-4.442995889759587),\n",
       " Row(label=-14.0, prediction=-11.081581316265725),\n",
       " Row(label=2.0, prediction=11.919468597771283),\n",
       " Row(label=-22.0, prediction=-11.891520141804108),\n",
       " Row(label=-5.0, prediction=-15.896908643057696),\n",
       " Row(label=2.0, prediction=-2.632890004297041),\n",
       " Row(label=65.0, prediction=18.268700864352304),\n",
       " Row(label=-9.0, prediction=1.4786448095580147),\n",
       " Row(label=-7.0, prediction=-5.505147931743718),\n",
       " Row(label=-30.0, prediction=-14.272926478489776),\n",
       " Row(label=-27.0, prediction=-15.472602522635253),\n",
       " Row(label=-26.0, prediction=-11.33497241924183),\n",
       " Row(label=-26.0, prediction=-11.33497241924183),\n",
       " Row(label=-25.0, prediction=-13.259515701957161),\n",
       " Row(label=-22.0, prediction=1.6686412677196056),\n",
       " Row(label=-22.0, prediction=-10.524940170794766),\n",
       " Row(label=-21.0, prediction=-9.866695849257077)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.select('label', 'prediction').head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19ff5b3e-71eb-4757-b1eb-3ba1f1d150c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/team37/.local/lib/python3.6/site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/team37/.local/lib/python3.6/site-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib64/python3.6/site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/team37/.local/lib/python3.6/site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib64/python3.6/site-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/team37/.local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/team37/.local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/team37/.local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas>=0.23->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3ebfdb5f-a3f4-4463-901b-962b306cb68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Root Mean Squared Error (RMSE) on test data = 33.1919\n",
      "R-squared (R²) on test data = 0.0691811\n",
      "Median Error on test data = 13.8038\n",
      "9\n",
      "Best maxDepth: 10\n",
      "Best maxIter: 10\n",
      "Best stepSize: 0.1\n",
      "Root Mean Squared Error (RMSE) on test data = 31.7836\n",
      "R-squared (R²) on test data = 0.146493\n",
      "Values with difference more than 15 percentage: 57.45%\n",
      "Values with difference more than 30 percentage: 85.17%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Transformer, Pipeline\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCols\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler,StandardScaler, Word2Vec, Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import os\n",
    "\n",
    "# Add here your team number teamx\n",
    "team = 37\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "spark.sql(\"USE team37_projectdb\")\n",
    "flights = spark.read.format(\"avro\").table('team37_projectdb.flight_data_bucketed')\n",
    "routes = spark.read.format(\"avro\").table('team37_projectdb.route_data_partitioned')\n",
    "airports = spark.read.format(\"avro\").table('team37_projectdb.airports_data_load').withColumnRenamed(\"latitude\", \"origin_latitude\").withColumnRenamed(\"longitude\", \"origin_longitude\")\n",
    "airports1 = spark.read.format(\"avro\").table('team37_projectdb.airports_data_load').withColumnRenamed(\"latitude\", \"dest_latitude\").withColumnRenamed(\"longitude\", \"dest_longitude\").withColumnRenamed(\"airport_name\", \"dest_airport_name\")\n",
    "df = flights.join(routes, on='route_id', how='inner')\n",
    "df = df.join(airports1, df.dest == airports1.dest_airport_name, how='inner')\n",
    "df = df.join(airports, df.origin == airports.airport_name, how='inner')\n",
    "class Encoder(Transformer, HasInputCol, HasOutputCols,\n",
    "              DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def __init__(self, inputCol, outputCols, n):\n",
    "        super(Encoder, self).__init__()\n",
    "        self._set(inputCol=inputCol, outputCols=outputCols)\n",
    "        self.n = n\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        input_col = self.getInputCol()\n",
    "        output_cols = self.getOutputCols()\n",
    "        dataset = dataset.withColumn(output_cols[0],\n",
    "                                     F.sin(2 * math.pi*F.col(input_col) / self.n))\n",
    "        return dataset\n",
    "\n",
    "\n",
    "df = df.withColumn(\"year\", F.year(\"fl_date\"))\n",
    "df = df.withColumn(\"month\", F.month(\"fl_date\"))\n",
    "df = df.withColumn(\"day\", F.dayofmonth(\"fl_date\"))\n",
    "df = Encoder(\"month\", [\"month\"], 12).transform(df)\n",
    "df = Encoder(\"day\", [\"day\"], 31).transform(df)\n",
    "from pyspark.sql.functions import col, floor, abs\n",
    "def split_time(column_name):\n",
    "    hours = floor(col(column_name) / 100).alias(f\"{column_name}_hours\")\n",
    "    minutes = floor(col(column_name) % 100).alias(f\"{column_name}_minutes\")\n",
    "    return hours, minutes\n",
    "time_columns = [\"crs_dep_time\",\"crs_arr_time\", \"arr_time\"]\n",
    "for col_name in time_columns:\n",
    "    hours, minutes = split_time(col_name)\n",
    "    df = df.withColumn(f\"{col_name}_hours\", hours)\n",
    "    df = df.withColumn(f\"{col_name}_minutes\", minutes)\n",
    "df = df.withColumn(\"delta_minutes\", (col(\"crs_arr_time_hours\") * 60 + col(\"crs_arr_time_minutes\") - col(\"crs_dep_time_hours\") * 60 - col(\"crs_dep_time_minutes\")))\n",
    "df = Encoder(\"crs_dep_time_hours\", [\"crs_dep_time_hours\"], 24).transform(df)\n",
    "df = Encoder(\"crs_arr_time_hours\", [\"crs_arr_time_hours\"], 24).transform(df)\n",
    "df = Encoder(\"arr_time_hours\", [\"arr_time_hours\"], 24).transform(df)\n",
    "features = ['arr_delay', 'crs_elapsed_time', 'year', 'month', 'day', 'airport_name', 'dest_latitude', 'dest_longitude', 'origin_latitude', 'origin_longitude', 'crs_dep_time_hours', 'crs_arr_time_hours', 'delta_minutes']\n",
    "df_filtered = df.select(*features)\n",
    "df_filtered = df_filtered.withColumnRenamed(\"arr_delay\",\"label\")\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler,StandardScaler, Word2Vec, Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col\n",
    "categoricalCols = ['airport_name']\n",
    "others = ['crs_elapsed_time', 'year', 'month', 'day', 'dest_latitude', 'dest_longitude', 'origin_latitude', 'origin_longitude', 'crs_dep_time_hours', 'crs_arr_time_hours', 'delta_minutes']\n",
    "\n",
    "# StringIndexer for categorical columns\n",
    "indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)).setHandleInvalid(\"skip\") for c in categoricalCols ]\n",
    "\n",
    "# OneHotEncoder for indexed categorical columns\n",
    "encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers ]\n",
    "\n",
    "# VectorAssembler to combine all features into a single vector\n",
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders] + others, outputCol=\"features\")\n",
    "\n",
    "# StandardScaler to scale the features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "\n",
    "# Create the pipeline with all stages\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "model = pipeline.fit(df_filtered)\n",
    "\n",
    "# Transform the data\n",
    "data = model.transform(df_filtered)\n",
    "#  split the data into 60% training and 40% test (it is not stratified)\n",
    "(train_data, test_data) = data.randomSplit([0.7, 0.3], seed = 10)\n",
    "\n",
    "\n",
    "# A function to run commands\n",
    "\n",
    "def run(command):\n",
    "    return os.popen(command).read()\n",
    "\n",
    "train_data.select(\"scaledFeatures\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/train\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/train/*.json > data/train.json\")\n",
    "\n",
    "test_data.select(\"scaledFeatures\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/test\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/test/*.json > data/test.json\")\n",
    "print(8)\n",
    "  # Example model, replace with your actual model\n",
    "\n",
    "# Assuming you have already created a DataFrame 'data' and split it into training and test sets\n",
    "# train_data, test_data = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a LinearRegression instance (replace with your actual model)\n",
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "\n",
    "# Create a ParamGridBuilder and add the parameters to search over\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator instance\n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "\n",
    "\n",
    "predictions = cvModel.transform(test_data)\n",
    "# Evaluate the performance of the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(\"R-squared (R²) on test data = %g\" % r2)\n",
    "\n",
    "# Calculate the absolute error\n",
    "predictions = predictions.withColumn(\"error\", F.abs(predictions[\"label\"] - predictions[\"prediction\"]))\n",
    "\n",
    "# Calculate the median error\n",
    "median_error = predictions.approxQuantile(\"error\", [0.5], 0.01)[0]\n",
    "print(\"Median Error on test data = %g\" % median_error)\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "\n",
    "parameters = {\n",
    "    'maxDepth': [5, 10],\n",
    "    'maxIter': [5, 10]\n",
    "}\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, parameters['maxDepth'])\n",
    "             .addGrid(gbt.maxIter, parameters['maxIter'])\n",
    "             .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                          numFolds=3)\n",
    "\n",
    "cvModel = crossval.fit(train_data)\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "bestMaxDepth = bestModel._java_obj.getMaxDepth()\n",
    "bestMaxIter = bestModel._java_obj.getMaxIter()\n",
    "bestStepSize = bestModel._java_obj.getStepSize()\n",
    "\n",
    "print(f\"Best maxDepth: {bestMaxDepth}\")\n",
    "print(f\"Best maxIter: {bestMaxIter}\")\n",
    "print(f\"Best stepSize: {bestStepSize}\")\n",
    "\n",
    "predictions = cvModel.transform(test_data)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R-squared (R²) on test data = %g\" % r2)\n",
    "\n",
    "predictions = predictions.withColumn(\"difference\", abs(predictions[\"prediction\"] - predictions[\"label\"]))\n",
    "\n",
    "filtered_predictions = predictions.filter(predictions[\"difference\"] > 15)\n",
    "count_filtered = filtered_predictions.count()\n",
    "total_count = predictions.count()\n",
    "percentage = 100 - (count_filtered / total_count) * 100\n",
    "print(f\"Values with difference more than 15 percentage: {percentage:.2f}%\")\n",
    "\n",
    "predictions = predictions.withColumn(\"difference\", abs(predictions[\"prediction\"] - predictions[\"label\"]))\n",
    "\n",
    "# Фильтрация строк, где разница больше 15\n",
    "filtered_predictions = predictions.filter(predictions[\"difference\"] > 30)\n",
    "\n",
    "# Подсчет количества строк, удовлетворяющих условию\n",
    "count_filtered = filtered_predictions.count()\n",
    "\n",
    "# Подсчет общего количества строк\n",
    "total_count = predictions.count()\n",
    "\n",
    "# Вычисление процента\n",
    "percentage = 100 - (count_filtered / total_count) * 100\n",
    "\n",
    "print(f\"Values with difference more than 30 percentage: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c741fbc5-23c7-48c9-a485-c357274df5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(crs_dep_time=1100, crs_arr_time=1145, delta_minutes=-45),\n",
       " Row(crs_dep_time=1705, crs_arr_time=1750, delta_minutes=-45),\n",
       " Row(crs_dep_time=1130, crs_arr_time=1315, delta_minutes=-105),\n",
       " Row(crs_dep_time=635, crs_arr_time=1040, delta_minutes=-245),\n",
       " Row(crs_dep_time=615, crs_arr_time=830, delta_minutes=-135)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Transformer, Pipeline\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCols\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler,StandardScaler, Word2Vec, Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import os\n",
    "\n",
    "# Add here your team number teamx\n",
    "team = 37\n",
    "print(1)\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "print(2)\n",
    "spark.sql(\"USE team37_projectdb\")\n",
    "flights = spark.read.format(\"avro\").table('team37_projectdb.flight_data_bucketed')\n",
    "routes = spark.read.format(\"avro\").table('team37_projectdb.route_data_partitioned')\n",
    "airports = spark.read.format(\"avro\").table('team37_projectdb.airports_data_load').withColumnRenamed(\"latitude\", \"origin_latitude\").withColumnRenamed(\"longitude\", \"origin_longitude\")\n",
    "airports1 = spark.read.format(\"avro\").table('team37_projectdb.airports_data_load').withColumnRenamed(\"latitude\", \"dest_latitude\").withColumnRenamed(\"longitude\", \"dest_longitude\").withColumnRenamed(\"airport_name\", \"dest_airport_name\")\n",
    "df = flights.join(routes, on='route_id', how='inner')\n",
    "df = df.join(airports1, df.dest == airports1.dest_airport_name, how='inner')\n",
    "df = df.join(airports, df.origin == airports.airport_name, how='inner')\n",
    "print(3)\n",
    "class Encoder(Transformer, HasInputCol, HasOutputCols,\n",
    "              DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def __init__(self, inputCol, outputCols, n):\n",
    "        super(Encoder, self).__init__()\n",
    "        self._set(inputCol=inputCol, outputCols=outputCols)\n",
    "        self.n = n\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        input_col = self.getInputCol()\n",
    "        output_cols = self.getOutputCols()\n",
    "        dataset = dataset.withColumn(output_cols[0],\n",
    "                                     F.sin(2 * math.pi*F.col(input_col) / self.n))\n",
    "        return dataset\n",
    "\n",
    "\n",
    "df = df.withColumn(\"year\", F.year(\"fl_date\"))\n",
    "df = df.withColumn(\"month\", F.month(\"fl_date\"))\n",
    "df = df.withColumn(\"day\", F.dayofmonth(\"fl_date\"))\n",
    "df = Encoder(\"month\", [\"month\"], 12).transform(df)\n",
    "df = Encoder(\"day\", [\"day\"], 31).transform(df)\n",
    "from pyspark.sql.functions import col, floor, abs\n",
    "def split_time(column_name):\n",
    "    hours = floor(col(column_name) / 100).alias(f\"{column_name}_hours\")\n",
    "    minutes = floor(col(column_name) % 100).alias(f\"{column_name}_minutes\")\n",
    "    return hours, minutes\n",
    "print(4)\n",
    "time_columns = [\"crs_dep_time\",\"crs_arr_time\", \"arr_time\"]\n",
    "for col_name in time_columns:\n",
    "    hours, minutes = split_time(col_name)\n",
    "    df = df.withColumn(f\"{col_name}_hours\", hours)\n",
    "    df = df.withColumn(f\"{col_name}_minutes\", minutes)\n",
    "df = df.withColumn(\"delta_minutes\", (col(\"crs_arr_time_hours\") * 60 + col(\"crs_arr_time_minutes\") - col(\"crs_dep_time_hours\") * 60 - col(\"crs_dep_time_minutes\")))\n",
    "df = Encoder(\"crs_dep_time_hours\", [\"crs_dep_time_hours\"], 24).transform(df)\n",
    "df = Encoder(\"crs_arr_time_hours\", [\"crs_arr_time_hours\"], 24).transform(df)\n",
    "df = Encoder(\"arr_time_hours\", [\"arr_time_hours\"], 24).transform(df)\n",
    "df.select(\"crs_dep_time\",\"crs_arr_time\", \"delta_minutes\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e29035e8-69eb-45c5-b6fa-671a53fd959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(crs_dep_time_total_minutes=15.52914270615126)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\n",
    "    (col(\"crs_dep_time_hours\") * 60 + col(\"crs_dep_time_minutes\")).alias(\"crs_dep_time_total_minutes\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08eea0df-8ecd-483e-b36d-329ee37d7ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-5dcae70492d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delta_minutes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"crs_dep_time_hours\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"crs_dep_time_minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"crs_dep_time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"crs_arr_time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"delta_minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \"\"\"\n\u001b[1;32m   2476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2478\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"delta_minutes\", \"crs_dep_time_hours\"*60+\"crs_dep_time_minutes\")\n",
    "df.select(\"crs_dep_time\",\"crs_arr_time\", \"delta_minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
